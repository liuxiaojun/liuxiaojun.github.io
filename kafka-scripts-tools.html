<!DOCTYPE HTML>
<html>
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
    <meta name="Keywords" content="blog"/>
    <meta name="Description" content="blog"/>
    <title>Simple</title>
    <link rel="shortcut icon" href="/static/favicon.png"/>
    <link rel="stylesheet" type="text/css" href="/main.css" />
</head>
<body>
<div class="main">
    <div class="header">
    	<ul id="pages">
            <li><a href="/">home</a></li>
            <li><a href="/#/tags">tags</a></li>
            <li><a href="/#/archive">archive</a></li>
    	</ul>
    </div>
	<div class="wrap-header">
	<h1>
    <a href="/" id="title"></a>
	</h1>
	</div>
<div id="md" style="display: none;">
<!-- markdown -->
常见工具脚本大汇总

Kafka 默认提供了很多个命令行脚本，用于实现各种各样的功能和运维管理。

connect-standalone 和 connect-distributed ：

  用于实现 Kafka 与外部世界系统之间的数据传输。Kafka Connect 支持单节点的 Standalone 模式，也支持多节点的 Distributed 模式。这两个脚本分别是这两种模式下的启动脚本。

kafka-acls 脚本

  用于设置 Kafka 权限的，比如设置哪些用户可以访问 Kafka 的哪些主题之类的权限

kafka-broker-api-versions 脚本

  这个脚本的主要目的是验证不同 Kafka 版本之间服务器和客户端的适配性。

kafka-console-consumer 和 kafka-console-producer。

  TODO

kafka-producer-perf-test 和 kafka-consumer-perf-test

  分别是生产者和消费者的性能测试工具，非常实用

kafka-delegation-tokens

  它是管理 Delegation Token 的。基于 Delegation Token 的认证是一种轻量级的认证机制，补充了现有的 SASL 认证机制。

kafka-delete-records 脚本

  用于删除 Kafka 的分区消息。鉴于 Kafka 本身有自己的自动消息删除策略

kafka-dump-log 

  查看 Kafka 消息文件的内容，包括消息的各种元数据信息，甚至是消息体本身。

kafka-log-dirs

  查询各个 Broker 上的各个日志路径的磁盘占用情况。

kafka-mirror-maker

  实现 Kafka 集群间的消息同步的

kafka-preferred-replica-election

  执行 Preferred Leader 选举的。它可以为指定的主题执行“换 Leader”的操作。

kafka-reassign-partitions

  用于执行分区副本迁移以及副本文件路径迁移。

kafka-topics

  所有的主题管理操作，都是由该脚本来实现的。

kafka-run-class

  以用这个脚本执行任何带 main 方法的 Kafka 类。

kafka-server-start 和 kafka-server-stop

  是用于启动和停止 Kafka Broker 进程的。

kafka-streams-application-reset 脚本

  用来给 Kafka Streams 应用程序重设位移，以便重新消费数据

kafka-verifiable-producer 和 kafka-verifiable-consumer 脚本

  用来测试生产者和消费者功能的, Console Producer 和 Console Consumer 完全可以替代它们。

trogdor 脚本

  它是 Kafka 的测试框架，用于执行各种基准测试和负载测试。一般的 Kafka 用户应该用不到这个脚本。

===========

重点脚本操作

生产消息 ---

生产消息使用 kafka-console-producer 脚本即可，一个典型的命令如下所示：

$ bin/kafka-console-producer.sh --broker-list kafka-host:port --topic test-topic --request-required-acks -1 --producer-property compression.type=lz4

>

在这段命令中，我们指定生产者参数 acks 为 -1，同时启用了 LZ4 的压缩算法。这个脚本可以很方便地让我们使用控制台来向 Kafka 的指定主题发送消息。

消费消息 ---

如果要快速地消费主题中的数据来验证消息是否存在，运行 kafka-console-consumer 脚本应该算是最便捷的方法了。

$ bin/kafka-console-consumer.sh --bootstrap-server kafka-host:port --topic test-topic --group test-group --from-beginning --consumer-property enable.auto.commit=false 

注意，在这段命令中，我们指定了 group 信息。如果没有指定的话，每次运行 Console Consumer，它都会自动生成一个新的消费者组来消费。久而久之，你会发现你的集群中有大量的以 console-consumer 开头的消费者组。通常情况下，你最好还是加上 group。另外，from-beginning 等同于将 Consumer 端参数 auto.offset.reset 设置成 earliest，表明我想从头开始消费主题。如果不指定的话，它会默认从最新位移读取消息。如果此时没有任何新消息，那么该命令的输出为空，你什么都看不到。最后，我在命令中禁掉了自动提交位移。通常情况下，让 Console Consumer 提交位移是没有意义的，毕竟我们只是用它做一些简单的测试。

测试生产者性能 ---

测试生产者的脚本：kafka-producer-perf-test

$ bin/kafka-producer-perf-test.sh --topic test-topic --num-records 10000000 --throughput -1 --record-size 1024 --producer-props bootstrap.servers=kafka-host:port acks=-1 linger.ms=2000 compression.type=lz4

2175479 records sent, 435095.8 records/sec (424.90 MB/sec), 131.1 ms avg latency, 681.0 ms max latency.

4190124 records sent, 838024.8 records/sec (818.38 MB/sec), 4.4 ms avg latency, 73.0 ms max latency.

10000000 records sent, 737463.126844 records/sec (720.18 MB/sec), 31.81 ms avg latency, 681.00 ms max latency, 4 ms 50th, 126 ms 95th, 604 ms 99th, 672 ms 99.9th.

上述命令向指定主题发送了 1 千万条消息，每条消息大小是 1KB。该命令允许你在 producer-props 后面指定要设置的生产者参数，比如本例中的压缩算法、延时时间等。该命令的输出值得好好说一下。它会打印出测试生产者的吞吐量 (MB/s)、消息发送延时以及各种分位数下的延时。一般情况下，消息延时不是一个简单的数字，而是一组分布。或者说，我们应该关心延时的概率分布情况，仅仅知道一个平均值是没有意义的。这就是这里计算分位数的原因。通常我们关注到 99th 分位就可以了。比如在上面的输出中，99th 值是 604ms，这表明测试生产者生产的消息中，有 99% 消息的延时都在 604ms 以内。你完全可以把这个数据当作这个生产者对外承诺的 SLA。

测试消费者性能 ---

使用的是 kafka-consumer-perf-test 脚本

$ bin/kafka-consumer-perf-test.sh --broker-list kafka-host:port --messages 10000000 --topic test-topic

start.time, end.time, data.consumed.in.MB, MB.sec, data.consumed.in.nMsg, nMsg.sec, rebalance.time.ms, fetch.time.ms, fetch.MB.sec, fetch.nMsg.sec

2019-06-26 15:24:18:138, 2019-06-26 15:24:23:805, 9765.6202, 1723.2434, 10000000, 1764602.0822, 16, 5651, 1728.1225, 1769598.3012

虽然输出格式有所差别，但该脚本也会打印出消费者的吞吐量数据。比如本例中的 1723MB/s。有点令人遗憾的是，它没有计算不同分位数下的分布情况。因此，在实际使用过程中，这个脚本的使用率要比生产者性能测试脚本的使用率低。

查看主题消息总数 ---

$ bin/kafka-run-class.sh kafka.tools.GetOffsetShell --broker-list kafka-host:port --time -2 --topic test-topic

test-topic:0:0

test-topic:1:0

$ bin/kafka-run-class.sh kafka.tools.GetOffsetShell --broker-list kafka-host:port --time -1 --topic test-topic

test-topic:0:5500000

test-topic:1:5500000

我们要使用 Kafka 提供的工具类 GetOffsetShell 来计算给定主题特定分区当前的最早位移和最新位移，将两者的差值累加起来，就能得到该主题当前总的消息数。对于本例来说，test-topic 总的消息数为 5500000 + 5500000，等于 1100 万条。

查看消息文件数据 ---

$ bin/kafka-dump-log.sh --files ../data_dir/kafka_1/test-topic-1/00000000000000000000.log 

Dumping ../data_dir/kafka_1/test-topic-1/00000000000000000000.log

Starting offset: 0

baseOffset: 0 lastOffset: 14 count: 15 baseSequence: -1 lastSequence: -1 producerId: -1 producerEpoch: -1 partitionLeaderEpoch: 0 isTransactional: false isControl: false position: 0 CreateTime: 1561597044933 size: 1237 magic: 2 compresscodec: LZ4 crc: 646766737 isvalid: true

baseOffset: 15 lastOffset: 29 count: 15 baseSequence: -1 lastSequence: -1 producerId: -1 producerEpoch: -1 partitionLeaderEpoch: 0 isTransactional: false isControl: false position: 1237 CreateTime: 1561597044934 size: 1237 magic: 2 compresscodec: LZ4 crc: 3751986433 isvalid: true

......

如果只是指定 --files，那么该命令显示的是消息批次（RecordBatch）或消息集合（MessageSet）的元数据信息，比如创建时间、使用的压缩算法、CRC 校验值等。

想深入看一下每条具体的消息，那么就需要显式指定 --deep-iteration 参数

$ bin/kafka-dump-log.sh --files ../data_dir/kafka_1/test-topic-1/00000000000000000000.log --deep-iteration

Dumping ../data_dir/kafka_1/test-topic-1/00000000000000000000.log

Starting offset: 0

baseOffset: 0 lastOffset: 14 count: 15 baseSequence: -1 lastSequence: -1 producerId: -1 producerEpoch: -1 partitionLeaderEpoch: 0 isTransactional: false isControl: false position: 0 CreateTime: 1561597044933 size: 1237 magic: 2 compresscodec: LZ4 crc: 646766737 isvalid: true

| offset: 0 CreateTime: 1561597044911 keysize: -1 valuesize: 1024 sequence: -1 

。。。

baseOffset: 15 lastOffset: 29 count: 15 baseSequence: -1 lastSequence: -1 producerId: -1 producerEpoch: -1 partitionLeaderEpoch: 0 isTransactional: false isControl: false position: 1237 CreateTime: 1561597044934 size: 1237 magic: 2 compresscodec: LZ4 crc: 3751986433 isvalid: true

......

如果还想看消息里面的实际数据，那么还需要指定  --print-data-log 参数

$ bin/kafka-dump-log.sh --files ../data_dir/kafka_1/test-topic-1/00000000000000000000.log --deep-iteration --print-data-log

查询消费者组位移===

如何使用 kafka-consumer-groups 脚本查看消费者组位移

bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 --describe --group test-group

 CURRENT-OFFSET 表示该消费者当前消费的最新位移，LOG-END-OFFSET 表示对应分区最新生产消息的位移，LAG 列是两者的差值。CONSUMER-ID 是 Kafka 消费者程序自动生成的一个 ID
<!-- markdown end -->
</div>
<div class="entry" id="main">
<!-- content -->
<p>常见工具脚本大汇总</p>

<p>Kafka 默认提供了很多个命令行脚本，用于实现各种各样的功能和运维管理。</p>

<p>connect-standalone 和 connect-distributed ：</p>

<p>用于实现 Kafka 与外部世界系统之间的数据传输。Kafka Connect 支持单节点的 Standalone 模式，也支持多节点的 Distributed 模式。这两个脚本分别是这两种模式下的启动脚本。</p>

<p>kafka-acls 脚本</p>

<p>用于设置 Kafka 权限的，比如设置哪些用户可以访问 Kafka 的哪些主题之类的权限</p>

<p>kafka-broker-api-versions 脚本</p>

<p>这个脚本的主要目的是验证不同 Kafka 版本之间服务器和客户端的适配性。</p>

<p>kafka-console-consumer 和 kafka-console-producer。</p>

<p>TODO</p>

<p>kafka-producer-perf-test 和 kafka-consumer-perf-test</p>

<p>分别是生产者和消费者的性能测试工具，非常实用</p>

<p>kafka-delegation-tokens</p>

<p>它是管理 Delegation Token 的。基于 Delegation Token 的认证是一种轻量级的认证机制，补充了现有的 SASL 认证机制。</p>

<p>kafka-delete-records 脚本</p>

<p>用于删除 Kafka 的分区消息。鉴于 Kafka 本身有自己的自动消息删除策略</p>

<p>kafka-dump-log </p>

<p>查看 Kafka 消息文件的内容，包括消息的各种元数据信息，甚至是消息体本身。</p>

<p>kafka-log-dirs</p>

<p>查询各个 Broker 上的各个日志路径的磁盘占用情况。</p>

<p>kafka-mirror-maker</p>

<p>实现 Kafka 集群间的消息同步的</p>

<p>kafka-preferred-replica-election</p>

<p>执行 Preferred Leader 选举的。它可以为指定的主题执行“换 Leader”的操作。</p>

<p>kafka-reassign-partitions</p>

<p>用于执行分区副本迁移以及副本文件路径迁移。</p>

<p>kafka-topics</p>

<p>所有的主题管理操作，都是由该脚本来实现的。</p>

<p>kafka-run-class</p>

<p>以用这个脚本执行任何带 main 方法的 Kafka 类。</p>

<p>kafka-server-start 和 kafka-server-stop</p>

<p>是用于启动和停止 Kafka Broker 进程的。</p>

<p>kafka-streams-application-reset 脚本</p>

<p>用来给 Kafka Streams 应用程序重设位移，以便重新消费数据</p>

<p>kafka-verifiable-producer 和 kafka-verifiable-consumer 脚本</p>

<p>用来测试生产者和消费者功能的, Console Producer 和 Console Consumer 完全可以替代它们。</p>

<p>trogdor 脚本</p>

<p>它是 Kafka 的测试框架，用于执行各种基准测试和负载测试。一般的 Kafka 用户应该用不到这个脚本。</p>

<p>===========</p>

<p>重点脚本操作</p>

<p>生产消息 ---</p>

<p>生产消息使用 kafka-console-producer 脚本即可，一个典型的命令如下所示：</p>

<p>$ bin/kafka-console-producer.sh --broker-list kafka-host:port --topic test-topic --request-required-acks -1 --producer-property compression.type=lz4</p>

<p>&gt;</p>

<p>在这段命令中，我们指定生产者参数 acks 为 -1，同时启用了 LZ4 的压缩算法。这个脚本可以很方便地让我们使用控制台来向 Kafka 的指定主题发送消息。</p>

<p>消费消息 ---</p>

<p>如果要快速地消费主题中的数据来验证消息是否存在，运行 kafka-console-consumer 脚本应该算是最便捷的方法了。</p>

<p>$ bin/kafka-console-consumer.sh --bootstrap-server kafka-host:port --topic test-topic --group test-group --from-beginning --consumer-property enable.auto.commit=false </p>

<p>注意，在这段命令中，我们指定了 group 信息。如果没有指定的话，每次运行 Console Consumer，它都会自动生成一个新的消费者组来消费。久而久之，你会发现你的集群中有大量的以 console-consumer 开头的消费者组。通常情况下，你最好还是加上 group。另外，from-beginning 等同于将 Consumer 端参数 auto.offset.reset 设置成 earliest，表明我想从头开始消费主题。如果不指定的话，它会默认从最新位移读取消息。如果此时没有任何新消息，那么该命令的输出为空，你什么都看不到。最后，我在命令中禁掉了自动提交位移。通常情况下，让 Console Consumer 提交位移是没有意义的，毕竟我们只是用它做一些简单的测试。</p>

<p>测试生产者性能 ---</p>

<p>测试生产者的脚本：kafka-producer-perf-test</p>

<p>$ bin/kafka-producer-perf-test.sh --topic test-topic --num-records 10000000 --throughput -1 --record-size 1024 --producer-props bootstrap.servers=kafka-host:port acks=-1 linger.ms=2000 compression.type=lz4</p>

<p>2175479 records sent, 435095.8 records/sec (424.90 MB/sec), 131.1 ms avg latency, 681.0 ms max latency.</p>

<p>4190124 records sent, 838024.8 records/sec (818.38 MB/sec), 4.4 ms avg latency, 73.0 ms max latency.</p>

<p>10000000 records sent, 737463.126844 records/sec (720.18 MB/sec), 31.81 ms avg latency, 681.00 ms max latency, 4 ms 50th, 126 ms 95th, 604 ms 99th, 672 ms 99.9th.</p>

<p>上述命令向指定主题发送了 1 千万条消息，每条消息大小是 1KB。该命令允许你在 producer-props 后面指定要设置的生产者参数，比如本例中的压缩算法、延时时间等。该命令的输出值得好好说一下。它会打印出测试生产者的吞吐量 (MB/s)、消息发送延时以及各种分位数下的延时。一般情况下，消息延时不是一个简单的数字，而是一组分布。或者说，我们应该关心延时的概率分布情况，仅仅知道一个平均值是没有意义的。这就是这里计算分位数的原因。通常我们关注到 99th 分位就可以了。比如在上面的输出中，99th 值是 604ms，这表明测试生产者生产的消息中，有 99% 消息的延时都在 604ms 以内。你完全可以把这个数据当作这个生产者对外承诺的 SLA。</p>

<p>测试消费者性能 ---</p>

<p>使用的是 kafka-consumer-perf-test 脚本</p>

<p>$ bin/kafka-consumer-perf-test.sh --broker-list kafka-host:port --messages 10000000 --topic test-topic</p>

<p>start.time, end.time, data.consumed.in.MB, MB.sec, data.consumed.in.nMsg, nMsg.sec, rebalance.time.ms, fetch.time.ms, fetch.MB.sec, fetch.nMsg.sec</p>

<p>2019-06-26 15:24:18:138, 2019-06-26 15:24:23:805, 9765.6202, 1723.2434, 10000000, 1764602.0822, 16, 5651, 1728.1225, 1769598.3012</p>

<p>虽然输出格式有所差别，但该脚本也会打印出消费者的吞吐量数据。比如本例中的 1723MB/s。有点令人遗憾的是，它没有计算不同分位数下的分布情况。因此，在实际使用过程中，这个脚本的使用率要比生产者性能测试脚本的使用率低。</p>

<p>查看主题消息总数 ---</p>

<p>$ bin/kafka-run-class.sh kafka.tools.GetOffsetShell --broker-list kafka-host:port --time -2 --topic test-topic</p>

<p>test-topic:0:0</p>

<p>test-topic:1:0</p>

<p>$ bin/kafka-run-class.sh kafka.tools.GetOffsetShell --broker-list kafka-host:port --time -1 --topic test-topic</p>

<p>test-topic:0:5500000</p>

<p>test-topic:1:5500000</p>

<p>我们要使用 Kafka 提供的工具类 GetOffsetShell 来计算给定主题特定分区当前的最早位移和最新位移，将两者的差值累加起来，就能得到该主题当前总的消息数。对于本例来说，test-topic 总的消息数为 5500000 + 5500000，等于 1100 万条。</p>

<p>查看消息文件数据 ---</p>

<p>$ bin/kafka-dump-log.sh --files ../data<em>dir/kafka</em>1/test-topic-1/00000000000000000000.log </p>

<p>Dumping ../data<em>dir/kafka</em>1/test-topic-1/00000000000000000000.log</p>

<p>Starting offset: 0</p>

<p>baseOffset: 0 lastOffset: 14 count: 15 baseSequence: -1 lastSequence: -1 producerId: -1 producerEpoch: -1 partitionLeaderEpoch: 0 isTransactional: false isControl: false position: 0 CreateTime: 1561597044933 size: 1237 magic: 2 compresscodec: LZ4 crc: 646766737 isvalid: true</p>

<p>baseOffset: 15 lastOffset: 29 count: 15 baseSequence: -1 lastSequence: -1 producerId: -1 producerEpoch: -1 partitionLeaderEpoch: 0 isTransactional: false isControl: false position: 1237 CreateTime: 1561597044934 size: 1237 magic: 2 compresscodec: LZ4 crc: 3751986433 isvalid: true</p>

<p>......</p>

<p>如果只是指定 --files，那么该命令显示的是消息批次（RecordBatch）或消息集合（MessageSet）的元数据信息，比如创建时间、使用的压缩算法、CRC 校验值等。</p>

<p>想深入看一下每条具体的消息，那么就需要显式指定 --deep-iteration 参数</p>

<p>$ bin/kafka-dump-log.sh --files ../data<em>dir/kafka</em>1/test-topic-1/00000000000000000000.log --deep-iteration</p>

<p>Dumping ../data<em>dir/kafka</em>1/test-topic-1/00000000000000000000.log</p>

<p>Starting offset: 0</p>

<p>baseOffset: 0 lastOffset: 14 count: 15 baseSequence: -1 lastSequence: -1 producerId: -1 producerEpoch: -1 partitionLeaderEpoch: 0 isTransactional: false isControl: false position: 0 CreateTime: 1561597044933 size: 1237 magic: 2 compresscodec: LZ4 crc: 646766737 isvalid: true</p>

<p>| offset: 0 CreateTime: 1561597044911 keysize: -1 valuesize: 1024 sequence: -1 </p>

<p>。。。</p>

<p>baseOffset: 15 lastOffset: 29 count: 15 baseSequence: -1 lastSequence: -1 producerId: -1 producerEpoch: -1 partitionLeaderEpoch: 0 isTransactional: false isControl: false position: 1237 CreateTime: 1561597044934 size: 1237 magic: 2 compresscodec: LZ4 crc: 3751986433 isvalid: true</p>

<p>......</p>

<p>如果还想看消息里面的实际数据，那么还需要指定  --print-data-log 参数</p>

<p>$ bin/kafka-dump-log.sh --files ../data<em>dir/kafka</em>1/test-topic-1/00000000000000000000.log --deep-iteration --print-data-log</p>

<p>查询消费者组位移===</p>

<p>如何使用 kafka-consumer-groups 脚本查看消费者组位移</p>

<p>bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 --describe --group test-group</p>

<p>CURRENT-OFFSET 表示该消费者当前消费的最新位移，LOG-END-OFFSET 表示对应分区最新生产消息的位移，LAG 列是两者的差值。CONSUMER-ID 是 Kafka 消费者程序自动生成的一个 ID</p>
<!-- content end -->
</div>
<br>
<br>
    <div id="disqus_thread"></div>
	<div class="footer">
		<p>© Copyright 2014 by isnowfy, Designed by isnowfy</p>
	</div>
</div>
<script src="main.js"></script>
<script id="content" type="text/mustache">
    <h1>{{title}}</h1>
    <div class="tag">
    {{date}}
    {{#tags}}
    <a href="/#/tag/{{name}}">#{{name}}</a>
    {{/tags}}
    </div>
</script>
<script id="pagesTemplate" type="text/mustache">
    {{#pages}}
    <li>
        <a href="{{path}}">{{title}}</a>
    </li>
    {{/pages}}
</script>
<script>
$(document).ready(function() {
    $.ajax({
        url: "main.json",
        type: "GET",
        dataType: "json",
        success: function(data) {
            $("#title").html(data.name);
            var pagesTemplate = Hogan.compile($("#pagesTemplate").html());
            var pagesHtml = pagesTemplate.render({"pages": data.pages});
            $("#pages").append(pagesHtml);
            //path
            var path = "kafka-scripts-tools.html";
            //path end
            var now = 0;
            for (var i = 0; i < data.posts.length; ++i)
                if (path == data.posts[i].path)
                    now = i;
            var post = data.posts[now];
            var tmp = post.tags.split(" ");
            var tags = [];
            for (var i = 0; i < tmp.length; ++i)
                if (tmp[i].length > 0)
                    tags.push({"name": tmp[i]});
            var contentTemplate = Hogan.compile($("#content").html());
            var contentHtml = contentTemplate.render({"title": post.title, "tags": tags, "date": post.date});
            $("#main").prepend(contentHtml);
            if (data.disqus_shortname.length > 0) {
                var disqus_shortname = data.disqus_shortname;
                (function() {
                    var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
                    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
                    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
                })();
            }
        }
    });
});
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ["\\(", "\\)"]], processEscapes: true}});
</script>
</body>
</html>
